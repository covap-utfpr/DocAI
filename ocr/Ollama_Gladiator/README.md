# ğŸ§  Projeto Ollama Gladiator â€” OCR Multimodelo com LLMs Visuais

Bem-vindo ao **Ollama Gladiator**, um projeto de **OCR baseado em LLMs Multimodais**, utilizando **Ollama** como backend para execuÃ§Ã£o local dos modelos.

A proposta Ã© comparar o uso de diversos modelos de LLM â€œem uma arenaâ€ e comparar sua capacidade de extrair texto de imagens de forma estruturada.

---

## ğŸš€ Objetivo

O objetivo do projeto Ã© **extrair texto de imagens utilizando modelos multimodais do Ollama**, forÃ§ando uma saÃ­da **padronizada**.

Cada modelo processa a mesma imagem e gera:

- Arquivo `.txt` com as linhas OCR detectadas
- Arquivo `.json` estruturado a partir do OCR
- Resultados organizados por imagem **e por modelo**

Tudo isso de forma automatizada e totalmente local.

---

## ğŸ§  Tecnologias e Estrutura

- **Ollama**: ExecuÃ§Ã£o local dos modelos LLM (API REST na porta `11434`)
- **LLMs Visuais** (podem ser modificados conforme os modelos instalados em sua mÃ¡quina):
  - `llama3.2-vision`
  - `gemma3`
  - `ministral-3`
  - `qwen3-vl`
- **Prompt Engineering**: Controle rÃ­gido de formato de saÃ­da OCR
- **NDJSON Streaming**: Processamento contÃ­nuo da resposta dos modelos
- **Python**: OrquestraÃ§Ã£o, parsing e persistÃªncia dos resultados

---

## ğŸ› ï¸ InstalaÃ§Ã£o

### 1ï¸âƒ£ PrÃ©-requisitos

- Python **3.10+**
- Ollama instalado e funcional (disponivel em https://ollama.com/download)
- Modelos multimodais previamente baixados
- Ollama serve rodando em background.

Exemplo de ativaÃ§Ã£o do Ollama:
```bash
ollama serve
```

2ï¸âƒ£ DependÃªncias Python

Instale as dependÃªncias do projeto:
```bash
pip install -r requirements.txt
```

ğŸ–¼ï¸ Como usar
1ï¸âƒ£ Preparando as imagens

VocÃª pode fornecer:

1 - Um arquivo de imagem individual
2 - Um diretÃ³rio contendo vÃ¡rias imagens (recursivo)

ExtensÃµes suportadas:

.jpg .jpeg .png .bmp .tiff .webp

2ï¸âƒ£ ExecuÃ§Ã£o

â–¶ï¸ Processamento por arquivo
```bash
python3 ollama_extract.py imagem.jpg
```

â–¶ï¸ Processamento por diretÃ³rio
```bash
python3 ollama_extract.py pasta_de_imagens/
```

â–¶ï¸ MÃºltiplas entradas
```bash
python3 ollama_extract.py imagem1.png imagem2.jpg pasta/
```

O script:

Expande automaticamente os caminhos

Processa cada imagem com todos os modelos configurados

Salva os resultados separadamente por modelo

âš™ï¸ Funcionamento Interno

1 - A imagem Ã© convertida para Base64 para suportar o uso da API na porta 11434
2 - O modelo recebe:
2.1 - Um prompt extremamente restritivo podendo ser personalizado
2.2 - A imagem embutida
2.3 - O retorno vem em NDJSON streaming

As respostas sÃ£o concatenadas e separadas por linha. onde cada linha segue o formato:
```
OCR='texto', score=0.95, bbox=[x1,y1,x2,y2]
```
1 - O .txt Ã© salvo

2 - O .txt Ã© parseado em tokens

3 - Os tokens sÃ£o convertidos em .json

ğŸ“ Estrutura dos Arquivos
```
ollama_extract.py          # Script principal (OCR multimodelo)
Modules/
â”œâ”€â”€ config.py              # Parse dos arquivos OCR (.txt)
â”œâ”€â”€ json_processing.py     # Limpeza, conversÃ£o e salvamento em JSON
â”œâ”€â”€ path.py                # Gerenciamento de diretÃ³rios
images/                    # (Opcional) Pasta de imagens para ser carregado
results/                   # Resultados gerados por imagem e modelo
```

Exemplo de saÃ­da:
```
results/
â”œâ”€â”€ nota_fiscal_llama3.2-vision_ocr.txt
â”œâ”€â”€ nota_fiscal_llama3.2-vision.json
â”œâ”€â”€ nota_fiscal_gemma3_ocr.txt
â”œâ”€â”€ nota_fiscal_gemma3.json
```

##  ğŸ“Œ ObservaÃ§Ãµes finais
    O projeto ainda estÃ¡ em desenvolvimento â€” fique Ã  vontade para sugerir melhorias!