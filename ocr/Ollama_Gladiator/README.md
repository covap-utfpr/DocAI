# üß† Ollama Gladiator ‚Äî Benchmark de LLMs Multimodais Instalados via Ollama

Bem-vindo ao **Ollama Gladiator**, um projeto de **OCR baseado em LLMs Multimodais**, utilizando o **Ollama** como backend para execu√ß√£o local dos modelos multimodais instalados.

A proposta do projeto consiste na avalia√ß√£o comparativa de diferentes LLMs multimodais ‚Äúem uma arena‚Äù, com foco na extra√ß√£o de texto estruturado a partir de imagens.

---

## üöÄ Objetivo

O objetivo do projeto √© **extrair texto de imagens utilizando modelos multimodais do Ollama**, for√ßando uma sa√≠da **padronizada e estruturada**.

Cada modelo processa a mesma imagem e gera:

- Arquivo `.txt` com as linhas OCR detectadas
- Arquivo `.json` estruturado a partir do OCR
- Resultados organizados por imagem **e por modelo**

Tudo isso de forma automatizada e totalmente local.

---

## üß† Tecnologias e Estrutura

- **Ollama**: Execu√ß√£o local dos modelos LLM (API REST na porta `11434`)
- **LLMs Multimodais Visuais** (podem ser modificados conforme os modelos instalados)
  - `llama3.2-vision`
  - `gemma3`
  - `ministral-3`
  - `qwen3-vl`
- **Prompt Engineering**: Controle r√≠gido de formato de sa√≠da OCR
- **NDJSON Streaming**: Processamento cont√≠nuo da resposta dos modelos
- **Python**: Orquestra√ß√£o, parsing e persist√™ncia dos resultados

---

## üõ†Ô∏è Instala√ß√£o

### 1Ô∏è‚É£ Pr√©-requisitos

- Python **3.10+**
- Ollama instalado e funcional (dispon√≠vel em https://ollama.com/download)
- Modelos multimodais previamente baixados (dispon√≠vel em https://ollama.com/search?c=vision) 
- Servi√ßo do Ollama rodando em background

Exemplo de ativa√ß√£o do Ollama:
```bash
ollama serve
```

2Ô∏è‚É£ Depend√™ncias Python

Instale as depend√™ncias do projeto:
```bash
pip install -r requirements.txt
```

üñºÔ∏è Como usar
1Ô∏è‚É£ Preparando as imagens

Voc√™ pode fornecer:

1 - Um arquivo de imagem individual
2 - Um diret√≥rio contendo v√°rias imagens (recursivo)

Extens√µes suportadas:

.jpg .jpeg .png .bmp .tiff .webp

2Ô∏è‚É£ Execu√ß√£o

‚ñ∂Ô∏è Processamento por arquivo
```bash
python3 ollama_extract.py imagem.jpg
```

‚ñ∂Ô∏è Processamento por diret√≥rio
```bash
python3 ollama_extract.py pasta_de_imagens/
```

‚ñ∂Ô∏è M√∫ltiplas entradas
```bash
python3 ollama_extract.py imagem1.png imagem2.jpg pasta/
```

O script:

Expande automaticamente os caminhos

Processa cada imagem com todos os modelos configurados

Salva os resultados separadamente por modelo

‚öôÔ∏è Funcionamento Interno

1 - A imagem √© convertida para Base64 para suportar o uso da API na porta 11434
2 - O modelo recebe:
2.1 - Um prompt extremamente restritivo podendo ser personalizado
2.2 - A imagem embutida
2.3 - O retorno vem em NDJSON streaming

As respostas s√£o concatenadas e separadas por linha. onde cada linha segue o formato:
```
OCR='texto', score=0.95, bbox=[x1,y1,x2,y2]
```
1 - O .txt √© salvo

2 - O .txt √© parseado em tokens

3 - Os tokens s√£o convertidos em .json

üìÅ Estrutura dos Arquivos
```
ollama_extract.py          # Script principal (OCR multimodelo)
Modules/
‚îú‚îÄ‚îÄ config.py              # Parse dos arquivos OCR (.txt)
‚îú‚îÄ‚îÄ json_processing.py     # Limpeza, convers√£o e salvamento em JSON
‚îú‚îÄ‚îÄ path.py                # Gerenciamento de diret√≥rios
images/                    # (Opcional) Pasta de imagens para ser carregado
results/                   # Resultados gerados por imagem e modelo
```

Exemplo de sa√≠da:
```
results/
‚îú‚îÄ‚îÄ nota_fiscal_llama3.2-vision_ocr.txt
‚îú‚îÄ‚îÄ nota_fiscal_llama3.2-vision.json
‚îú‚îÄ‚îÄ nota_fiscal_gemma3_ocr.txt
‚îú‚îÄ‚îÄ nota_fiscal_gemma3.json
```

##  üìå Observa√ß√µes finais
    O projeto ainda est√° em desenvolvimento ‚Äî fique √† vontade para sugerir melhorias!
